{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e964491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best params: {'model__learning_rate': 0.1, 'model__l2_leaf_reg': 1, 'model__depth': 10}\n",
      "MAE  :  0.525\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "got an unexpected keyword argument 'squared'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 175\u001b[39m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TASK == \u001b[33m\"\u001b[39m\u001b[33mregression\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    174\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMAE  : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_absolute_error(y_test,\u001b[38;5;250m \u001b[39mpred)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m .3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRMSE : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43msquared\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m .3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mR²   : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr2_score(y_test,\u001b[38;5;250m \u001b[39mpred)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m .3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Arshil Jain\\myenv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:196\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m params = \u001b[43mfunc_sig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m params.apply_defaults()\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# ignore self/cls and positional/keyword markers\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\inspect.py:3280\u001b[39m, in \u001b[36mSignature.bind\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3275\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, /, *args, **kwargs):\n\u001b[32m   3276\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[32m   3277\u001b[39m \u001b[33;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[32m   3278\u001b[39m \u001b[33;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[32m   3279\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3280\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\inspect.py:3269\u001b[39m, in \u001b[36mSignature._bind\u001b[39m\u001b[34m(self, args, kwargs, partial)\u001b[39m\n\u001b[32m   3259\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   3260\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mgot some positional-only arguments passed as \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   3261\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mkeyword arguments: \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[33m'\u001b[39m.format(\n\u001b[32m   (...)\u001b[39m\u001b[32m   3266\u001b[39m             ),\n\u001b[32m   3267\u001b[39m         )\n\u001b[32m   3268\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3269\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   3270\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mgot an unexpected keyword argument \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[33m'\u001b[39m.format(\n\u001b[32m   3271\u001b[39m                 arg=\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))))\n\u001b[32m   3273\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_arguments_cls(\u001b[38;5;28mself\u001b[39m, arguments)\n",
      "\u001b[31mTypeError\u001b[39m: got an unexpected keyword argument 'squared'"
     ]
    }
   ],
   "source": [
    "# ----------------------- README.md -----------------------\n",
    "\"\"\"\n",
    "Order‑Delay Predictor\n",
    "=====================\n",
    "A streamlined project that predicts whether an Olist marketplace order will be\n",
    "delivered **late (1) or on time (0)**.  Fits in a single weekend build and\n",
    "covers practical skills expected for the Vinted Data Science & Analytics\n",
    "Academy: data wrangling, feature engineering, model training, evaluation, and\n",
    "a Streamlit demo.\n",
    "\n",
    "Quick‑start\n",
    "-----------\n",
    "```bash\n",
    "python -m venv .venv && source .venv/bin/activate\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# Step 1: preprocess & feature engineering\n",
    "python -m src.feature_engineering\n",
    "\n",
    "# Step 2: train + evaluation\n",
    "python -m src.train_model\n",
    "\n",
    "# Step 3: launch the Streamlit app\n",
    "streamlit run app/streamlit_app.py\n",
    "```\n",
    "\n",
    "Directory layout\n",
    "----------------\n",
    "```\n",
    "order_delay_predictor/\n",
    "├── app/\n",
    "│   └── streamlit_app.py\n",
    "├── src/\n",
    "│   ├── __init__.py\n",
    "│   ├── config.py\n",
    "│   ├── data_loader.py\n",
    "│   ├── feature_engineering.py\n",
    "│   ├── train_model.py\n",
    "│   └── predict.py\n",
    "└─ data\n",
    "   └─ raw\n",
    "      ├─ olist_customers_dataset.csv\n",
    "      ├─ olist_order_reviews_dataset.csv\n",
    "      ├─ olist_orders_dataset.csv\n",
    "      ├─ olist_products_dataset.csv\n",
    "      ├─ olist_sellers_dataset.csv\n",
    "      ├─ olist_geolocation_dataset.csv\n",
    "      ├─ olist_order_items_dataset.csv\n",
    "      ├─ olist_order_payments_dataset.csv\n",
    "      └─ product_category_name_translation.csv   ← ignored for now (name doesn’t start with “olist_”)\n",
    "\n",
    "├── models/\n",
    "├── requirements.txt\n",
    "└── README.md\n",
    "\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "# ----------------------- src/__init__.py -----------------------\n",
    "\"\"\"Package shortcut imports for notebooks and Streamlit.\"\"\"\n",
    "\n",
    "from .config import CFG\n",
    "from .predict import predict_delay\n",
    "\n",
    "# ----------------------- src/config.py -----------------------\n",
    "\"\"\"Centralised paths and hyper‑parameters.\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "class _CFG:\n",
    "    ROOT = Path(__file__).resolve().parents[2]\n",
    "    DATA_RAW = ROOT / \"data\" / \"raw\"\n",
    "    DATA_PROC = ROOT / \"data\" / \"processed\"\n",
    "    MODELS = ROOT / \"models\"\n",
    "\n",
    "    ORDERS_PARQUET = DATA_PROC / \"orders.parquet\"\n",
    "    TRAIN_TEST_PARQUET = DATA_PROC / \"train_test.parquet\"\n",
    "\n",
    "    CLF_PATH = MODELS / \"delay_clf.joblib\"\n",
    "    SCALER_PATH = MODELS / \"scaler.joblib\"\n",
    "\n",
    "    TEST_SIZE = 0.2\n",
    "    RANDOM_STATE = 42\n",
    "    TARGET_COL = \"is_late\"\n",
    "\n",
    "CFG = _CFG()\n",
    "\n",
    "# ----------------------- src/data_loader.py -----------------------\n",
    "\"\"\"Load and merge Olist CSVs into a single orders DataFrame.\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from .config import CFG\n",
    "\n",
    "def load_raw_tables():\n",
    "    prefix = CFG.DATA_RAW\n",
    "    files = {\n",
    "        f.stem: pd.read_csv(prefix / f)\n",
    "        for f in prefix.iterdir()\n",
    "        if f.suffix == \".csv\" and f.name.startswith(\"olist_\")\n",
    "    }\n",
    "    return files\n",
    "\n",
    "\n",
    "def build_orders():\n",
    "    tbl = load_raw_tables()\n",
    "    orders = tbl[\"olist_orders_dataset\"]\n",
    "    customers = tbl[\"olist_customers_dataset\"][[\"customer_id\", \"customer_zip_code_prefix\"]]\n",
    "    items = tbl[\"olist_order_items_dataset\"][\n",
    "        [\"order_id\", \"seller_id\", \"price\", \"freight_value\"]\n",
    "    ]\n",
    "    sellers = tbl[\"olist_sellers_dataset\"][[\"seller_id\", \"seller_zip_code_prefix\"]]\n",
    "\n",
    "    # Merge basic dimensions\n",
    "    df = (\n",
    "        orders.merge(customers, on=\"customer_id\", how=\"left\")\n",
    "        .merge(items.groupby(\"order_id\").agg({\"price\": \"sum\", \"freight_value\": \"sum\"}).reset_index(), on=\"order_id\", how=\"left\")\n",
    "        .merge(sellers, on=\"seller_id\", how=\"left\")\n",
    "    )\n",
    "\n",
    "    # Dates → datetime\n",
    "    for col in [\n",
    "        \"order_purchase_timestamp\",\n",
    "        \"order_approved_at\",\n",
    "        \"order_delivered_carrier_date\",\n",
    "        \"order_delivered_customer_date\",\n",
    "        \"order_estimated_delivery_date\",\n",
    "    ]:\n",
    "        df[col] = pd.to_datetime(df[col])\n",
    "\n",
    "    # Target: late if delivered after estimated date\n",
    "    df[CFG.TARGET_COL] = (df[\"order_delivered_customer_date\"] > df[\"order_estimated_delivery_date\"]).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "# ----------------------- src/feature_engineering.py -----------------------\n",
    "\"\"\"Create flat feature table and train/test split.\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "from .config import CFG\n",
    "from .data_loader import build_orders\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "CATEGORICAL = [\"order_status\", \"customer_zip_code_prefix\", \"seller_zip_code_prefix\"]\n",
    "NUMERIC = [\n",
    "    \"price\",\n",
    "    \"freight_value\",\n",
    "    \"days_estimated\",\n",
    "    \"order_hour\",\n",
    "    \"days_to_approve\",\n",
    "]\n",
    "\n",
    "\n",
    "def engineer(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Simple numeric features\n",
    "    df[\"days_estimated\"] = (\n",
    "        (df[\"order_estimated_delivery_date\"] - df[\"order_purchase_timestamp\"]).dt.days\n",
    "    )\n",
    "    df[\"order_hour\"] = df[\"order_purchase_timestamp\"].dt.hour\n",
    "    df[\"days_to_approve\"] = (\n",
    "        (df[\"order_approved_at\"] - df[\"order_purchase_timestamp\"]).dt.total_seconds() / 3600\n",
    "    )\n",
    "    df[\"days_to_approve\"].fillna(df[\"days_to_approve\"].median(), inplace=True)\n",
    "\n",
    "    # Drop high‑cardinality IDs\n",
    "    drop_cols = [\n",
    "        \"order_id\",\n",
    "        \"customer_id\",\n",
    "        \"seller_id\",\n",
    "        \"order_purchase_timestamp\",\n",
    "        \"order_approved_at\",\n",
    "        \"order_delivered_customer_date\",\n",
    "        \"order_estimated_delivery_date\",\n",
    "    ]\n",
    "    return df.drop(columns=drop_cols)\n",
    "\n",
    "\n",
    "def main():\n",
    "    CFG.DATA_PROC.mkdir(parents=True, exist_ok=True)\n",
    "    df = build_orders()\n",
    "    df = engineer(df)\n",
    "\n",
    "    # Train/test split & save scaler for numeric cols\n",
    "    train_df, test_df = train_test_split(\n",
    "        df, test_size=CFG.TEST_SIZE, random_state=CFG.RANDOM_STATE, stratify=df[CFG.TARGET_COL]\n",
    "    )\n",
    "    scaler = StandardScaler()\n",
    "    train_df[NUMERIC] = scaler.fit_transform(train_df[NUMERIC])\n",
    "    test_df[NUMERIC] = scaler.transform(test_df[NUMERIC])\n",
    "\n",
    "    train_df.to_parquet(CFG.DATA_PROC / \"train.parquet\", index=False)\n",
    "    test_df.to_parquet(CFG.DATA_PROC / \"test.parquet\", index=False)\n",
    "    joblib.dump(scaler, CFG.SCALER_PATH)\n",
    "\n",
    "    print(f\"✔ Processed data saved to {CFG.DATA_PROC}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# ----------------------- src/train_model.py -----------------------\n",
    "\"\"\"Train delay classifier and output metrics.\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "from .config import CFG\n",
    "from .feature_engineering import CATEGORICAL, NUMERIC\n",
    "\n",
    "\n",
    "def main():\n",
    "    train_df = pd.read_parquet(CFG.DATA_PROC / \"train.parquet\")\n",
    "    test_df = pd.read_parquet(CFG.DATA_PROC / \"test.parquet\")\n",
    "\n",
    "    X_train = train_df.drop(columns=[CFG.TARGET_COL])\n",
    "    y_train = train_df[CFG.TARGET_COL]\n",
    "    X_test = test_df.drop(columns=[CFG.TARGET_COL])\n",
    "    y_test = test_df[CFG.TARGET_COL]\n",
    "\n",
    "    preproc = ColumnTransformer([\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), CATEGORICAL),\n",
    "        (\"num\", \"passthrough\", NUMERIC),\n",
    "    ])\n",
    "\n",
    "    clf = GradientBoostingClassifier(random_state=CFG.RANDOM_STATE)\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"preproc\", preproc),\n",
    "        (\"clf\", clf),\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    joblib.dump(pipe, CFG.CLF_PATH)\n",
    "\n",
    "    preds = pipe.predict(X_test)\n",
    "    print(\"\\n--- Classification Report ---\")\n",
    "    print(classification_report(y_test, preds, digits=3))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, preds))\n",
    "    print(f\"✔ Model saved to {CFG.CLF_PATH}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# ----------------------- src/predict.py -----------------------\n",
    "\"\"\"Inference helper for Streamlit or external usage.\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from .config import CFG\n",
    "from .feature_engineering import CATEGORICAL, NUMERIC\n",
    "\n",
    "# Load model once at import time\n",
    "_MODEL = joblib.load(CFG.CLF_PATH)\n",
    "_SCALER = joblib.load(CFG.SCALER_PATH)\n",
    "\n",
    "\n",
    "def predict_delay(row: dict):\n",
    "    \"\"\"Take a dict of order features (raw) → probability of delay (0‑1).\"\"\"\n",
    "    df = pd.DataFrame([row])\n",
    "    # Numeric scaling (Streamlit supplies raw values)\n",
    "    df[NUMERIC] = _SCALER.transform(df[NUMERIC])\n",
    "    proba = _MODEL.predict_proba(df)[:, 1][0]\n",
    "    return proba\n",
    "\n",
    "# ----------------------- app/streamlit_app.py -----------------------\n",
    "\"\"\"Simple Streamlit front‑end.\"\"\"\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "from src.predict import predict_delay\n",
    "from src.feature_engineering import NUMERIC, CATEGORICAL\n",
    "\n",
    "st.set_page_config(page_title=\"Order Delay Predictor\", layout=\"centered\")\n",
    "\n",
    "st.title(\"🚚 Order‑Delay Predictor (Olist)\")\n",
    "\n",
    "with st.form(\"delay_form\"):\n",
    "    st.markdown(\"#### Enter order details\")\n",
    "    order_status = st.selectbox(\"Order status\", [\"processing\", \"shipped\", \"delivered\"])\n",
    "    cust_zip = st.text_input(\"Customer ZIP prefix\", \"01086\")\n",
    "    seller_zip = st.text_input(\"Seller ZIP prefix\", \"04538\")\n",
    "    price = st.number_input(\"Total item price (R$)\", min_value=0.0, value=100.0)\n",
    "    freight = st.number_input(\"Freight value (R$)\", min_value=0.0, value=15.0)\n",
    "    days_est = st.slider(\"Estimated delivery days\", 1, 20, 5)\n",
    "    order_hour = st.slider(\"Purchase hour (0‑23)\", 0, 23, 14)\n",
    "    days_to_appr = st.slider(\"Hours to approve\", 0, 72, 4)\n",
    "\n",
    "    submitted = st.form_submit_button(\"Predict delay risk →\")\n",
    "\n",
    "if submitted:\n",
    "    row = {\n",
    "        \"order_status\": order_status,\n",
    "        \"customer_zip_code_prefix\": cust_zip,\n",
    "        \"seller_zip_code_prefix\": seller_zip,\n",
    "        \"price\": price,\n",
    "        \"freight_value\": freight,\n",
    "        \"days_estimated\": days_est,\n",
    "        \"order_hour\": order_hour,\n",
    "        \"days_to_approve\": days_to_appr,\n",
    "    }\n",
    "    proba = predict_delay(row)\n",
    "    st.subheader(\"Result\")\n",
    "    st.metric(\"Probability of being late\", f\"{proba:.2%}\")\n",
    "    if proba > 0.5:\n",
    "        st.error(\"⚠️ High risk of delay. Consider proactive communication with the buyer.\")\n",
    "    else:\n",
    "        st.success(\"✅ Likely on‑time.\")\n",
    "\n",
    "# ----------------------- requirements.txt -----------------------\n",
    "pandas>=2.0\n",
    "numpy>=1.24\n",
    "scikit-learn>=1.4\n",
    "joblib>=1.4\n",
    "streamlit>=1.35\n",
    "tqdm>=4.66\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
